Первый индекс который мы разберём это индекс типа "ключ - значение". Это один из самых распространенных индексов, а так же база для более сложных индексов.

Хранилища данных типа "ключ - значение" - очень распространена в разных языках и называется как словарь. Хеш-карты описываются во многих языках программирования. Такой подход часто используется в памяти, для хранения данных в оперативной памяти.

Если развивать прошлую мысль про db_set, то для хеш-карты в оперативной памяти потребуется в качестве ключа хранить, соответствующее значение места в файле данных. При добавлении новой пары "ключ-значение" происходит так же обновление хеш-карты для отражения в ней относительного адреса, только что записанных данных, это работает как и при вставке новых ключей, так и при обновлении существующих. Если нужно будет найти значение, используем хеш-карту, сразу переходим к нужному месту и читаем значение.

Данных прием хоть и простой, но он жизнеспособен, фактически этот механизм использует Bitcask в своей NoSQL СУБД Riak. Bitcask обеспечивает высокую скорость для записи и чтения, а так же требует, чтобы все ключи помещались в оперативной памяти, хеш-карта целиком хранится в оперативной памяти. Значения могут использовать пространства больше, чем есть у оперативной памяти, поскольку их можно загрузить с диска за один переход к нужной позиции. Если данных уже находятся в кэше, то не потребуется дополнительной операции ввода-вывода.

Такая подсистема Bitcask, отлично подходит для частого обновления всех ключей. Например ключи могут быть URL, а значение - это количество просмотров. При таком типе нагрузки, операций для записи будет очень много, но уникальных ключей не слишком много, все это можно хранить в оперативной памяти.

Мы пока записываем данные в конец файла, но что если место на диске закончится? Можно закрывать файл, при достижении определенного размера, а после выполнять уплотнение, у нас это будет удаление дублирующих ключей в файле. Если идти дальше и уплотнение очень эффективно работает(много дублирующих записей), то можно после уплотнять несколько файлов в один. Такое слияние и уплотнение "замороженных" файлов можно выполнять в фоновом режиме. По завершению слияния можно переключать запросы на чтение, чтобы применять новые объединенные сегменты место старых, старые файлы просто удалять.

У каждого сегмента есть своя хеш-таблица в оперативной памяти, если мы не нашли свой ключ в хеш-карте, переходим к следующему сегменту по времени создания. Благодаря слиянию и уплотнению таких файлов будет немного.

Чтобы воплотить эту идею в жизнь, есть не мало нюансов, которые стоит предусмотреть. Вот краткий перечень вопросов:
1. Формат файлов. CSV - не лучший формат данных для журнала. Лучше будет пользоваться двоичным форматом, который сначала кодируется в байтах длина строки, а затем - строка неформатированных данных(нужны в экранировании нет).
2. Удаление записей. При удалении определенного ключа, потребуется удалить его из всех файлов. Обычно ставятся отметку удаления(tombstone), а после фоновый процесс удаляет все эти ключи из файлов.
3. Восстановление после сбоев. При записке системы, все данные в хеш-карте потеряются. Можно написать алгоритм, который будет при перезапуске системы смотреть все файлы и снова восстанавливать хеш-карту. Но если размер базы данных велик, то такой процесс может занять много времени, потому как восстановление системы займет большую часть времени. Можно поступить как Bitcask, мы будем хранить копию хеш-карты на жестком диске, которые можно будет загрузить в память достаточно быстро.
4. Недописанные записи. Фатальный сбой базы данных может произойти на момент записи  в базу, на такой счет у Bitcask есть алгоритм контрольных сумм, это позволяет обнаруживать и игнорировать поврежденные части журналов.
5. Управление конкурентным доступом. Поскольку запись происходит в конец файла и в обычной реализации записывает его один поток, тут проблем нет. Файлы только дописываются, в остальных случаях неизменяемые, поэтому чтение нескольких потоков произойдет без проблем.

На первый взгляд идея записывать каждое новое значение в конец файла, выглядит не лучшей реализацией. Почему бы не обновлять старую запись при обновлении? Но наш первоначальный вариант выглядит лучше по нескольким причинам:
1. Добавление в конец записи и слияния сегментов - последовательные операции записи, в большинстве случаев это намного быстрее случайной записи, особенно на магнитных жестких дисках. Последовательная запись предпочтительна больше для SSD. Позже в этой главе  мы обсудим эту тему подробнее.
2. Конкурентный доступ и восстановление после сбоев сильно упрощается, когда значения только добавляются, а старые не изменяются. Например, не нужно заботиться об изменении старого значения, приводящих в результате к файлу, в котором склеены воедино части старого и нового значений.

У хеш-индексов тоже есть ограничения:
1. Если у нас очень много ключей, то поддерживать такую хеш-карту на оперативной памяти очень сложно. Можно сделать это с жёстким диском, но производительность такой системы будет сильно слабее. Это потребует больших ресурсов ввода-вывода, а расширение при заполнении - дорогостоящая операция, а разрешение конфликтов кеша требует запутанной логики.
2. Запросу по диапазону неэффективны, например просмотреть все записи с kitty00000 и kitty99999 - необходимо будет искать каждый ключ отдельно в хеш-карте. У [[SS таблицы и LSM деревья]], такой проблемы нет
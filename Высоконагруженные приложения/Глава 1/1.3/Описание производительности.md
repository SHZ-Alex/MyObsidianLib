После определение нагрузки на систему, можно выявить, что произойдет при её возрастании. Следует обратить внимание на два аспекта

 1. Как изменится производительность системы, если увеличить нагрузку при неизменных ресурсов CPU, RAM, Сеть?
 2. На сколько нужно увеличить ресурсы при увеличении параметров нагрузки, чтобы производительность системы не изменилась?
 
Для ответа на эти вопросы нужны характеристики производительности.

Разных системах смотрят на разные параметры, где-то на скорость пакетной обработки, но на веб-сервисах часто смотрят на время ответа сервиса.

Время ответа - это время между отправкой запроса клиентом и получении ответа. Время ожидания(latency) и время отклика(response time) это разные свойства, хоть их и путают. Время отклика - фактическое время работы сервера, которое обслуживает запрос. Грубо говоря, время ответа это время ответа сервера + затраты на транспортировку по сети.

Если мы будем делать запросы подряд, время будет отличаться, когда-то сильно, когда-то незначительно, следует это рассматривать не как одно число, а как распределение значений. Иногда появляются аномально высокие запросы, может произойти очень много, сборка мусора, протокол TCP не доставил данные и повторно отправляет пакет, переключение потоков, механические вибрации в серверной стойке.

Часто выводят среднее время ответов, но среднее далеко не лучшая метрика. Удобная метрика это процентили. Например медиана может быть 200 мс., получается одна часть пользователей получает данные быстро, а другие ждут дольше, медиана это середина p50 - 50ая процентиль, чтобы выяснить аномальные значения. лучше смотреть на 95ый, 99ый, 99.9ый процентили. Например на 95ом процентили запросы отрабатывают 1.5 секунды, значит что 95% быстрее 1.5 секунд, а 5% дольше этого времени.

Например компания Амазон смотрит на 99.9 процентиль(дальше 999), часто это те клиенты, кто довольны сервисом и у них больше всего данных в аккаунте. Там же Амазон выявила, что рост времени отклика на 100 мс, снижает продажи на 1%, а по другим сообщениям, замедление на 1с снижает удовлетворенность пользователей на 16%.

С другой стороны оптимизация 1 из 1000 запросов, достаточно дорогостоющая практика. снижать время отлика на 999 процентили очень сложно, могут происходить разные события независящие от разработчиков, а выгода минимальная. 

Другие компании часто описываю в SLO и SLA процентили и требования к ним, может быть описан медианный ответ, 95, 99ый процентиль и в целом время работы всего сервиса. Благодаря этому, бизнес может прогнозировать и ожидать от работы сервиса. А если метрики не выполяются, можно потребовать возмещение по SLA

Значительную часть времени в верхних процентилях может отвечать какие-то долгие и процессы и переключение в ядрах процессора, когда нагрузка высокая возврастает среднее время ответа, при этом если какие-то запросы медленные, то от этого могут пострадать и другие запросы - это явление называется блокировкой головы очереди. 

При написании нагрузочных тестов, нужно отправлять запросы постоянно, а не дожидаться окончания предыдущих, если ожидать, то на деле, это не будет имитацией реальных запросов со стороны клиентов.

В прикладных приложения клиент делает несколько запросов и обычно страница прогружается когда все запросы отработали и получили данные, если сервис делает 9 запросов, 8 отработали за 200мс, а один за 1с, то страница не загрузится быстро за 200 мс, это явление называется **усиление "хвостатового" времени ожидания**. Поэтому можно замерять загрузку целого окна и возможно один запрос будет останавливать загрузку окна.